from flask import Flask, request, jsonify
import sys
import os
from pathlib import Path
from flask_cors import CORS
from run import run
import json
import base64
import traceback
from board import Board
import datetime
import threading
import random
import string
from upload import upload_jlc, upload_euro, upload_aisler

from server_packets import (
    PCBArtifactRequest, 
    PCBArtifactResponse, 
    RoutingProgressRequest, 
    RoutingProgressResponse, 
    RoutingStartRequest, 
    RoutingStartResponse
)

# Add the parent directory to the Python path if needed
sys.path.append(str(Path(__file__).parent))

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# Could be anything really, necessary for reading, the file writtien within the request cycle
file_number = 9999

# NOTE: /app/storage is the persistent storage folder in the docker container
job_folder_base = Path("./storage/jobs")

# The user doesn't need to know about these sorts of errors, enough to throw them and check the logs
def validate_endpoint(data, endpoint):
    if data.get("endpoint") != endpoint:
        raise ValueError(f"Invalid endpoint: {data.get('endpoint')}. Expected: {endpoint}")

def project_to_legacy_json(project_string):
    """ 
    Converts a MakeDevice-new Project JSON string to the legacy format used by the backend.
    """
    # Parse the project data as JSON
    project_json = json.loads(project_string)

    # data_template.json contains lots of fields from the legacy format, we'll use it as a basis for porting
    # over the data from Project  TODO: Move away from the legacy format completely
    data_template_file = Path("./data_template.json")
    data_template = None
    with open(data_template_file, 'r') as template_file:
        data_template = json.load(template_file)

    # WARN: Unclear if custom names are supported, since all our previous data files were just called MakeDevice
    # data_template["board"]["name"] = project_json.get("name")
    data_template["board"]["id"] = project_json.get("id") # New
    data_template["board"]["last_modified"] = project_json.get("lastModified") # New
    data_template["board"]["generation_software"]["version"] = str(project_json.get("projectVersion"))
    data_template["board"]["size"]["x"] = project_json.get("size").get("width")
    data_template["board"]["size"]["y"] = project_json.get("size").get("height")
    data_template["configuration"]["fabrication_options"]["rounded_corner_radius"] = project_json.get("pcbOptions").get("cornerRadius")
    data_template["configuration"]["fabrication_options"]["connectors"]["top"] = project_json.get("pcbOptions").get("connectors").get("top")
    data_template["configuration"]["fabrication_options"]["connectors"]["bottom"] = project_json.get("pcbOptions").get("connectors").get("bottom")
    data_template["configuration"]["fabrication_options"]["house_name"] = project_json.get("pcbOptions").get("fabricationHouse") # New, needed for uploading

    # HACK: Hardcoded mapping of all mm_* to ec30_* from modules/
    # TODO: Store as mm_* in modules/, shouldn't be called ec30_* in modules/, the footprints aren't even generic
    mm_to_ec30_mapping = {
        "mm_jacdaptor": "ec30_1x7_r6_mh_0.1",
        "mm_keycap_button": "ec30_3x2_lr_mh_0.1",
        "mm_light_sensor": "ec30_2x2_lr_mh_0.1",
        "mm_rgb_ring": "ec30_3x3_l_mh_0.1",
        "mm_rotary_button": "ec30_3x2_lr_mh_0.1"
    }

    # Convert all Project InstanceModules to the legacy format
    for m in project_json.get("modules"):
        instance = {
            "name": m.get("name") + "_" + m.get("version"),
            "position": {
                "x": m.get("position").get("x"),
                "y": -m.get("position").get("y")
            },
            "rotation": (360 - m.get("rotation")) % 360,  # Swap rotation direction
            "id": m.get("id"), # New, but needed for routing feedback
        }
        # Convert mounted modules to ec30_*
        if m.get("name").startswith("mm_"):
            ec30_name = mm_to_ec30_mapping.get(m.get("name"))
            if ec30_name:
                instance["name"] = ec30_name

        data_template["modules"].append(instance)

    return data_template

def generate_id(length=8): # Was using import uuid, but this is simpler
    chars = string.ascii_letters + string.digits  # A-Z, a-z, 0-9
    return ''.join(random.choices(chars, k=length))

# TODO: Implement these new endpoints properly
@app.route('/routingStart', methods=['POST'])
def routing_start():
    data: RoutingStartRequest = request.get_json(force=True)
    validate_endpoint(data, "routingStart")

    # Job ID is generated by the backend (to ensure no folder name conflicts)
    job_id = generate_id()

    # Create a temporary working folder named after the job_id
    job_folder = job_folder_base / Path(f"./{job_id}") 
    output_folder = job_folder / "output"
    output_folder.mkdir(parents=True, exist_ok=True)
    print(f"ðŸ”µ Created job folder: {job_folder}")
    print(f"ðŸ”µ Created output folder: {output_folder}")

    # Create a file to store the project data
    project_file = output_folder / "project.MakeDevice"
    with open(project_file, 'w') as file:
        file.write(data["project"])
    print(f"ðŸ”µ Project data saved to: {project_file}")

    # The keepalive file is changed by routingProgress periodically to keep the job alive
    keepalive_file = job_folder / "keepalive_time"
    with open(keepalive_file, 'w') as file:
        file.write("!") # Anything

    data = project_to_legacy_json(data["project"])

    # Write the data template to a file
    data_file = job_folder / "data.json"
    with open(data_file, 'w') as file:
        json.dump(data, file, indent=2)

    print(f"ðŸ”µ Project converted to legacy data format, stored at: {data_file}")

    print(f"ðŸ”µ Starting routing with job ID: {job_id}")


    # TODO: Trigger routing in a different thread to allow responding to the client
    # run() or whatever, and create a temp working folder for the job_id
    threading.Thread(target=run, args=("from_server", True, job_id, str(job_folder))).start()

    response: RoutingStartResponse = {
        "endpoint": "routingStart",
        "result": {
            "jobId": job_id
        }
    }
    return jsonify(response), 200


# TODO: Implement these new endpoints properly
# 
# A nice to have would be an error if the server crashed since starting the routing, 
# and so the job isn't running anymore. Could just add the jobId to a list when first 
# calling run(), and if the jobId isn't in the list then the server has crashed/restarted 
# since starting the job.
@app.route('/routingProgress', methods=['POST'])
def routing_progress():
    data: RoutingProgressRequest = request.get_json(force=True)
    validate_endpoint(data, "routingProgress")

    job_id = data["jobId"]

    # Check if the job_id folder exists
    if not os.path.exists(job_folder_base / job_id):
        response: RoutingProgressResponse = {
            "endpoint": "routingProgress",
            "error": {
                "message": f"Job ID {job_id} does not exist.",
                "failedModuleIds": [], #TODO: Make this field optional in front and back ends
            }
        }
        return jsonify(response), 200

    # Check if there's an output.zip file
    zip_path = job_folder_base / job_id / "output.zip"
    # FIX: Use a better method for checking if routing succeeded?
    finished_success = os.path.exists(zip_path)

    # TODO: Store some progress image(s) too
    progress_file = job_folder_base / job_id / "progress.txt"
    progress = 0.0
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as file:
            progress = float(file.read().strip())

    # The keepalive file is changed to keep the job alive
    keepalive_file = job_folder_base / job_id / "keepalive_time"
    with open(keepalive_file, 'w') as file:
        file.write("!") # Anything

    # Check for routing failure
    error_file = job_folder_base / job_id / "error.txt"
    routing_failed = os.path.exists(error_file)
    error_message = ""

    if routing_failed:
        try:
            with open(error_file, 'r') as file:
                error_message = file.read().strip()
        except:
            error_message = "Unknown routing error occurred"

    # Get routing image
    routing_imgs_folder = job_folder_base / job_id / "routing_imgs"
    routing_image = None
    if os.path.exists(routing_imgs_folder):
        # All the routing images
        routing_images = list(routing_imgs_folder.glob("*.png"))
        if len(routing_images):
            # Sort by filename, which is the number
            routing_images.sort(key=lambda x: int(x.stem))
            # Get the second highest numbered routing image (since the highest
            # numbered may not have finished writing to disk yet), by removing the last one
            # routing_images = routing_images[:-1]
            routing_image = routing_images[-1] if len(routing_images) else None

    # Get routing image in base64
    routing_image_base64 = None
    if routing_image:
        try:
            with open(routing_image, 'rb') as img_file:
                routing_image_data = img_file.read()
            routing_image_base64 = base64.b64encode(routing_image_data).decode('utf-8')
        except Exception as e:
            print(f"ðŸ”´ Error reading routing image {routing_image}: {e}")

    if routing_failed:
        response: RoutingProgressResponse = {
            "endpoint": "routingProgress",
            "error": {
                "message": error_message,
                "failedModuleIds": [],  # TODO: Implement
                "succeededModuleIds": [],  # TODO: Implement
            }
        }
        return jsonify(response), 200
    else:
        response: RoutingProgressResponse = {
            "endpoint": "routingProgress",
            "result": {
                "progress": progress,
                "completed": finished_success,
                "routingImage": str(routing_image_base64),
                # TODO: Implement bus width left and right
            }
        }
        return jsonify(response), 200


# TODO: Implement these new endpoints properly
@app.route('/pcbArtifact', methods=['POST'])
def pcb_artifact():
    data: PCBArtifactRequest = request.get_json(force=True)
    validate_endpoint(data, "pcbArtifact")

    job_id = data.get("jobId")

    # Check if the job_id folder exists
    if not os.path.exists(job_folder_base / job_id):
        response: PCBArtifactResponse = {
            "endpoint": "pcbArtifact",
            "error": {
                "message": f"Job ID {job_id} does not exist.",
            }
        }
        return jsonify(response), 200

    zip_path = job_folder_base / job_id / "output.zip"
    # Check if there's an output.zip file
    if not os.path.exists(zip_path):
        response: PCBArtifactResponse = {
            "endpoint": "pcbArtifact",
            "error": {
                "message": "Routing still in progress or stuck.",
            }
        }
        return jsonify(response), 200

    # Zip present in job folder...

    url = None
    should_upload = data.get("uploadToFabHouse", False)
    if should_upload:
        try:
            # Get the fabrication house used when routing the job
            with open(job_folder_base / job_id / "data.json", 'r') as data_file:
                data_json = json.load(data_file)
            fabrication_house = data_json.get("configuration").get("fabrication_options").get("house_name")

            print("ðŸŸ¢ Uploading files to fabrication service")

            if fabrication_house == "JLCPCB":
                url = upload_jlc(zip_path)
            elif fabrication_house == "Eurocircuits":    
                url = upload_euro(zip_path)
            elif fabrication_house == "Aisler":
                url = upload_aisler(zip_path)
            else:
                print(f"ðŸ”´ Unsupported fabrication house for upload: {fabrication_house}")
        except Exception as e:
            print(f"ðŸ”´ Exception during fabrication house upload: {e}")

    # Base64 encode zip
    with open(job_folder_base / job_id / "output.zip", 'rb') as zip_file:
        zip_data = zip_file.read()
    encoded_zip = base64.b64encode(zip_data).decode('utf-8')

    # Form the response
    response: PCBArtifactResponse = {
        "endpoint": "pcbArtifact",
    }
    if url:
        response["result"] = {
            "zipFile": encoded_zip,
            "fabricationUrl": url
        }
    else:
        response["result"] = {
            "zipFile": encoded_zip,
        }

    # NOTE: Still use status code 200 for application-level errors, since we want the custom error message
    return jsonify(response), 200

# Setup server
if __name__ == '__main__':
    # Default to port 5000 or use environment variable if specified
    port = int(os.environ.get("PORT", 3333))

    # Run the Flask app, enabling debug mode for development
    app.run(host='0.0.0.0', port=port, debug=True)
