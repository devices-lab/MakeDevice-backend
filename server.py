from flask import Flask, request, jsonify
import sys
import os
from pathlib import Path
from flask_cors import CORS
from run import run
import json
import base64
import threading
import random
import string

from upload import upload_jlc, upload_euro, upload_aisler

from server_packets import (
    PCBArtifactRequest, 
    PCBArtifactResponse, 
    RoutingProgressRequest, 
    RoutingProgressResponse, 
    RoutingStartRequest, 
    RoutingStartResponse
)

# Add the parent directory to the Python path if needed
sys.path.append(str(Path(__file__).parent))

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# NOTE: /app/storage is the persistent storage folder in the docker container
job_folder_base = Path("./storage/jobs")

# The user doesn't need to know about these sorts of errors, enough to throw them and check the logs
def validate_endpoint(data: RoutingStartRequest, endpoint: str):
    if data.get("endpoint") != endpoint:
        raise ValueError(f"Invalid endpoint: {data.get('endpoint')}. Expected: {endpoint}")

def generate_id(length=8): # Was using import uuid, but this is simpler
    chars = string.ascii_letters + string.digits  # A-Z, a-z, 0-9
    return ''.join(random.choices(chars, k=length))

# TODO: Implement these new endpoints properly
@app.route('/routingStart', methods=['POST'])
def routing_start():
    data: RoutingStartRequest = request.get_json(force=True)
    validate_endpoint(data, "routingStart")

    # Job ID is generated by the backend (to ensure no folder name conflicts)
    job_id = generate_id()

    # Create a temporary working folder named after the job_id
    job_folder = job_folder_base / Path(f"./{job_id}") 
    output_folder = job_folder / "output"
    output_folder.mkdir(parents=True, exist_ok=True)
    print(f"ðŸ”µ Created job folder: {job_folder}")
    print(f"ðŸ”µ Created output folder: {output_folder}")

    # Create a file to store the project data
    project_file_path = output_folder / "project.MakeDevice"
    with open(project_file_path, 'w') as file:
        file.write(data["project"])
    print(f"ðŸ”µ Project data saved to: {project_file_path}")

    # The keepalive file is changed by routingProgress periodically to keep the job alive
    keepalive_file = job_folder / "keepalive_time"
    with open(keepalive_file, 'w') as file:
        file.write("!") # Anything

    print(f"ðŸ”µ Starting routing with job ID: {job_id}")

    # TODO: Trigger routing in a different thread to allow responding to the client
    # run() or whatever, and create a temp working folder for the job_id
    threading.Thread(target=run, args=(job_id, job_folder)).start()

    response: RoutingStartResponse = {
        "endpoint": "routingStart",
        "result": {
            "jobId": job_id
        }
    }
    return jsonify(response), 200

# TODO: Implement these new endpoints properly
# 
# A nice to have would be an error if the server crashed since starting the routing, 
# and so the job isn't running anymore. Could just add the jobId to a list when first 
# calling run(), and if the jobId isn't in the list then the server has crashed/restarted 
# since starting the job.
@app.route('/routingProgress', methods=['POST'])
def routing_progress():
    data: RoutingProgressRequest = request.get_json(force=True)
    validate_endpoint(data, "routingProgress")

    job_id = data["jobId"]

    # Check if the job_id folder exists
    if not os.path.exists(job_folder_base / job_id):
        response: RoutingProgressResponse = {
            "endpoint": "routingProgress",
            "error": {
                "message": f"Job ID {job_id} does not exist.",
                "failedModuleIds": [], #TODO: Make this field optional in front and back ends
            }
        }
        return jsonify(response), 200

    # Check if there's an output.zip file
    zip_path = job_folder_base / job_id / "output.zip"
    # FIX: Use a better method for checking if routing succeeded?
    finished_success = os.path.exists(zip_path)

    # TODO: Store some progress image(s) too
    progress_file = job_folder_base / job_id / "progress.txt"
    progress = 0.0
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as file:
            progress = float(file.read().strip())

    # The keepalive file is changed to keep the job alive
    keepalive_file = job_folder_base / job_id / "keepalive_time"
    with open(keepalive_file, 'w') as file:
        file.write("!") # Anything

    # Check for routing failure
    error_file = job_folder_base / job_id / "error.txt"
    routing_failed = os.path.exists(error_file)
    error_message = ""

    if routing_failed:
        try:
            with open(error_file, 'r') as file:
                error_message = file.read().strip()
        except:
            error_message = "Unknown routing error occurred"

    # Get routing image
    routing_imgs_folder = job_folder_base / job_id / "routing_imgs"
    routing_image = None
    if os.path.exists(routing_imgs_folder):
        # All the routing images
        routing_images = list(routing_imgs_folder.glob("*.png"))
        if len(routing_images):
            # Sort by filename, which is the number
            routing_images.sort(key=lambda x: int(x.stem))
            # Get the second highest numbered routing image (since the highest
            # numbered may not have finished writing to disk yet), by removing the last one
            # routing_images = routing_images[:-1]
            routing_image = routing_images[-1] if len(routing_images) else None

    # Get routing image in base64
    routing_image_base64 = None
    if routing_image:
        try:
            with open(routing_image, 'rb') as img_file:
                routing_image_data = img_file.read()
            routing_image_base64 = base64.b64encode(routing_image_data).decode('utf-8')
        except Exception as e:
            print(f"ðŸ”´ Error reading routing image {routing_image}: {e}")

    if routing_failed:
        response: RoutingProgressResponse = {
            "endpoint": "routingProgress",
            "error": {
                "message": error_message,
                "failedModuleIds": [],  # TODO: Implement
                "succeededModuleIds": [],  # TODO: Implement
            }
        }
        return jsonify(response), 200
    else:
        response: RoutingProgressResponse = {
            "endpoint": "routingProgress",
            "result": {
                "progress": progress,
                "completed": finished_success,
                "routingImage": str(routing_image_base64),
                # TODO: Implement bus width left and right
            }
        }
        return jsonify(response), 200


# TODO: Split the artifact download and the fabrication house upload into two endpoints
@app.route('/pcbArtifact', methods=['POST'])
def pcb_artifact():
    data: PCBArtifactRequest = request.get_json(force=True)
    validate_endpoint(data, "pcbArtifact")

    job_id = data.get("jobId")

    # Check if the job_id folder exists
    if not os.path.exists(job_folder_base / job_id):
        response: PCBArtifactResponse = {
            "endpoint": "pcbArtifact",
            "error": {
                "message": f"Job ID {job_id} does not exist.",
            }
        }
        return jsonify(response), 200

    zip_path = job_folder_base / job_id / "output.zip"
    # Check if there's an output.zip file
    if not os.path.exists(zip_path):
        response: PCBArtifactResponse = {
            "endpoint": "pcbArtifact",
            "error": {
                "message": "Routing still in progress or stuck.",
            }
        }
        return jsonify(response), 200

    # Zip present in job folder...

    url = None
    should_upload = data.get("uploadToFabHouse", False)
    if should_upload:
        try:
            # Get the fabrication house used when routing the job
            with open(job_folder_base / job_id / "output/project.MakeDevice", 'r') as data_file:
                data_json = json.load(data_file)
            fabrication_house = data_json.get("pcbOptions", {}).get("fabricationHouse", "")

            print("ðŸŸ¢ Uploading files to fabrication service")

            if fabrication_house == "JLCPCB":
                url = upload_jlc(zip_path)
            elif fabrication_house == "Eurocircuits":    
                url = upload_euro(zip_path)
            elif fabrication_house == "Aisler":
                url = upload_aisler(zip_path)
            else:
                print(f"ðŸ”´ Unsupported fabrication house for upload: {fabrication_house}")
        except Exception as e:
            print(f"ðŸ”´ Exception during fabrication house upload: {e}")

    # Base64 encode zip
    with open(job_folder_base / job_id / "output.zip", 'rb') as zip_file:
        zip_data = zip_file.read()
    encoded_zip = base64.b64encode(zip_data).decode('utf-8')

    # Form the response
    response: PCBArtifactResponse = {
        "endpoint": "pcbArtifact",
    }
    if url:
        response["result"] = {
            "zipFile": encoded_zip,
            "fabricationUrl": url
        }
    else:
        response["result"] = {
            "zipFile": encoded_zip,
        }

    # NOTE: Still use status code 200 for application-level errors, since we want the custom error message
    return jsonify(response), 200

# Setup server
if __name__ == '__main__':
    # Default to port 5000 or use environment variable if specified
    port = int(os.environ.get("PORT", 3333))

    # Run the Flask app, enabling debug mode for development
    app.run(host='0.0.0.0', port=port, debug=True)
